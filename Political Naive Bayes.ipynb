{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/halledavis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install mysql-connector\n",
    "#!pip install mosestokenizer\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import html\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "import regex as re\n",
    "import glob\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "sw = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    counter = Counter()\n",
    "    tokens.map(counter.update)\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    counter_df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "    num_tokens = sum(freq_df['freq'])\n",
    "    num_unique_tokens = freq_df.shape[0]\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum((counter_df['index'].str.len()) * counter_df[0])\n",
    "\n",
    "    if verbose :\n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        print(f\"The top 5 most common words are\")\n",
    "        print(counter.most_common(5))\n",
    "\n",
    "    return(0)\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    return [t for t in tokens if t.lower() not in stopwords]\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r'\\S+', text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text) # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"2020_Conventions.db\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conventions',)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"\"\"SELECT name FROM sqlite_schema\n",
    "WHERE type='table'\n",
    "ORDER BY name;\"\"\")\n",
    "\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql(\"\"\"\n",
    "                        SELECT *\n",
    "                        FROM conventions;\n",
    "                        \"\"\",\n",
    "                        conn)\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tokens\"] = data[\"text\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cleantext\"] = data[\"text\"].apply(clean)\n",
    "data[\"cleantext\"] = data[\"cleantext\"].apply(str.lower)\n",
    "data[\"cleantext\"] = data[\"cleantext\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>night</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_count</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>file</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Skip to content The Company Careers Press Free...</td>\n",
       "      <td>127</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "      <td>[skip, content, company, careers, press, freel...</td>\n",
       "      <td>skip to content the company careers press free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:33</td>\n",
       "      <td>Iâ€™m here by calling the full session of the 48...</td>\n",
       "      <td>41</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "      <td>[iâ€™m, calling, full, session, 48th, quadrennia...</td>\n",
       "      <td>iâ€™m here by calling the full session of the 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1</td>\n",
       "      <td>00:59</td>\n",
       "      <td>Every four years, we come together to reaffirm...</td>\n",
       "      <td>17</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "      <td>[every, four, years, come, together, reaffirm,...</td>\n",
       "      <td>every four years we come together to reaffirm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Kerry Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>01:07</td>\n",
       "      <td>We fight for a more perfect union because we a...</td>\n",
       "      <td>28</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "      <td>[fight, perfect, union, fighting, soul, countr...</td>\n",
       "      <td>we fight for a more perfect union because we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>1</td>\n",
       "      <td>01:18</td>\n",
       "      <td>We must come together to defeat Donald Trump, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "      <td>[must, come, together, defeat, donald, trump, ...</td>\n",
       "      <td>we must come together to defeat donald trump a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        party  night           speaker  speaker_count   time  \\\n",
       "0  Democratic      4           Unknown              1  00:00   \n",
       "1  Democratic      4         Speaker 1              1  00:33   \n",
       "2  Democratic      4         Speaker 2              1  00:59   \n",
       "3  Democratic      4  Kerry Washington              1  01:07   \n",
       "4  Democratic      4    Bernie Sanders              1  01:18   \n",
       "\n",
       "                                                text text_len  \\\n",
       "0  Skip to content The Company Careers Press Free...      127   \n",
       "1  Iâ€™m here by calling the full session of the 48...       41   \n",
       "2  Every four years, we come together to reaffirm...       17   \n",
       "3  We fight for a more perfect union because we a...       28   \n",
       "4  We must come together to defeat Donald Trump, ...       22   \n",
       "\n",
       "                                                file  \\\n",
       "0  www_rev_com_blog_transcripts2020-democratic-na...   \n",
       "1  www_rev_com_blog_transcripts2020-democratic-na...   \n",
       "2  www_rev_com_blog_transcripts2020-democratic-na...   \n",
       "3  www_rev_com_blog_transcripts2020-democratic-na...   \n",
       "4  www_rev_com_blog_transcripts2020-democratic-na...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [skip, content, company, careers, press, freel...   \n",
       "1  [iâ€™m, calling, full, session, 48th, quadrennia...   \n",
       "2  [every, four, years, come, together, reaffirm,...   \n",
       "3  [fight, perfect, union, fighting, soul, countr...   \n",
       "4  [must, come, together, defeat, donald, trump, ...   \n",
       "\n",
       "                                           cleantext  \n",
       "0  skip to content the company careers press free...  \n",
       "1  iâ€™m here by calling the full session of the 48...  \n",
       "2  every four years we come together to reaffirm ...  \n",
       "3  we fight for a more perfect union because we a...  \n",
       "4  we must come together to defeat donald trump a...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convention_data = []\n",
    "\n",
    "#query_results = cursor.execute(\"\"\"SELECT text, party\n",
    "#                        FROM conventions;\"\"\")\n",
    "\n",
    "\n",
    "#for row in query_results :\n",
    "#    convention_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = data[[\"cleantext\", \"party\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = query_results.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2510 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline2 = [str.lower, tokenize]\n",
    "\n",
    "data[\"tokens\"] = data[\"cleantext\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    tokenfw = {}\n",
    "    tokens = tokenize(text)\n",
    "    for token in tokens:\n",
    "        if token in fw :\n",
    "            tokenfw[token] = True\n",
    "        #    tokenfw.append(\n",
    "        #    {\n",
    "        #        token,\n",
    "        #        True\n",
    "        #    }\n",
    "        #)\n",
    "            \n",
    "    return(tokenfw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1\n",
      "{'donald': True, 'is': True, 'the': True, 'president': True}\n",
      "\n",
      " Test 2\n",
      "{'people': True, 'are': True, 'american': True, 'in': True, 'america': True}\n"
     ]
    }
   ],
   "source": [
    "assert(len(feature_words)>0)\n",
    "print(\"Test 1\")\n",
    "print(conv_features(\"donald is the president\",feature_words))\n",
    "print(\"\\n Test 2\")\n",
    "print(conv_features(\"people are american in america\",feature_words))\n",
    "#assert(conv_features(\"donald is the president\",feature_words)== {'donald':True,'president':True})\n",
    "#assert(conv_features(\"people are american in america\",feature_words)=={'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featuresets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "Right off the bat, I notice the word \"J.\" -- I would love to see this in context, but my guess is this is in reference to the name \"Donald J. Trump\". I think it's interesting because it shows that Republicans are more likely to add the middle initial when referencing President Trump, which makes sense because it's slightly more honorific. It also makes sense that \"Lady\" would be on their list because that are more likely to make reference to First Lady Melania Trump.\n",
    "\n",
    "I notice that \"great\" and \"first\" are associated with Republicans, which makes sense because it's associated with kep slogans or policies that Republicans had at the time (America First and Make America Great Again). \n",
    "\n",
    "After that I just see key policy differences between Republicans and Democrats: enforcement, media, destroy, China, private, freedom, defund, and preserve, all seem related to Republican concerns or traditional philosophies. Alternatively, Democrats have \"votes\" and \"climate\", which related to climate change and protecting the right to vote.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultsdf = pd.DataFrame(results, columns=['author', 'party', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for row in resultsdf[\"text\"]:\n",
    "    try:\n",
    "        text.append(row.decode())\n",
    "    except:\n",
    "        text.append(row.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf[\"text\"] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf[\"tokens\"] = resultsdf[\"text\"].apply(prepare,pipeline=my_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdf[\"cleantext\"] = resultsdf[\"text\"].apply(clean)\n",
    "resultsdf[\"cleantext\"] = resultsdf[\"cleantext\"].apply(str.lower)\n",
    "resultsdf[\"cleantext\"] = resultsdf[\"cleantext\"].apply(remove_punctuation)\n",
    "\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"Brooks Joins Alabama Delegation in Voting Aga...</td>\n",
       "      <td>[brooks, joins, alabama, delegation, voting, f...</td>\n",
       "      <td>brooks joins alabama delegation in voting agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"Brooks: Senate Democrats Allowing President t...</td>\n",
       "      <td>[brooks, senate, democrats, allowing, presiden...</td>\n",
       "      <td>brooks senate democrats allowing president to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"NASA on the Square\" event this Sat. 11AM â€“ 4P...</td>\n",
       "      <td>[nasa, square, event, sat, 11am, â€“, 4pm, stop,...</td>\n",
       "      <td>nasa on the square event this sat 11am â€“ 4pm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"The trouble with Socialism is that eventually...</td>\n",
       "      <td>[trouble, socialism, eventually, run, peoples,...</td>\n",
       "      <td>the trouble with socialism is that eventually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mo Brooks</td>\n",
       "      <td>Republican</td>\n",
       "      <td>\"The trouble with socialism is eventually you ...</td>\n",
       "      <td>[trouble, socialism, eventually, run, peoples,...</td>\n",
       "      <td>the trouble with socialism is eventually you r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664651</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>We had a great time at the WVU Homecoming para...</td>\n",
       "      <td>[great, time, wvu, homecoming, parade, yesterd...</td>\n",
       "      <td>we had a great time at the wvu homecoming para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664652</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>We need more transparency in Washington #wvpol...</td>\n",
       "      <td>[need, transparency, washington, #wvpol, https...</td>\n",
       "      <td>we need more transparency in washington #wvpol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664653</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>We saw there is a double standard in DC and th...</td>\n",
       "      <td>[saw, double, standard, dc, rules, simply, don...</td>\n",
       "      <td>we saw there is a double standard in dc and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664654</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Wow! Huge crowd in Charleston at the @WVGOP vi...</td>\n",
       "      <td>[wow, huge, crowd, charleston, wvgop, victory,...</td>\n",
       "      <td>wow huge crowd in charleston at the wvgop vict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664655</th>\n",
       "      <td>David McKinley</td>\n",
       "      <td>Republican</td>\n",
       "      <td>https://t.co/0QmZlRfEcD https://t.co/FY520NC2GB</td>\n",
       "      <td>[httpstco0qmzlrfecd, httpstcofy520nc2gb]</td>\n",
       "      <td>httpstco0qmzlrfecd httpstcofy520nc2gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>664656 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author       party  \\\n",
       "0            Mo Brooks  Republican   \n",
       "1            Mo Brooks  Republican   \n",
       "2            Mo Brooks  Republican   \n",
       "3            Mo Brooks  Republican   \n",
       "4            Mo Brooks  Republican   \n",
       "...                ...         ...   \n",
       "664651  David McKinley  Republican   \n",
       "664652  David McKinley  Republican   \n",
       "664653  David McKinley  Republican   \n",
       "664654  David McKinley  Republican   \n",
       "664655  David McKinley  Republican   \n",
       "\n",
       "                                                     text  \\\n",
       "0       \"Brooks Joins Alabama Delegation in Voting Aga...   \n",
       "1       \"Brooks: Senate Democrats Allowing President t...   \n",
       "2       \"NASA on the Square\" event this Sat. 11AM â€“ 4P...   \n",
       "3       \"The trouble with Socialism is that eventually...   \n",
       "4       \"The trouble with socialism is eventually you ...   \n",
       "...                                                   ...   \n",
       "664651  We had a great time at the WVU Homecoming para...   \n",
       "664652  We need more transparency in Washington #wvpol...   \n",
       "664653  We saw there is a double standard in DC and th...   \n",
       "664654  Wow! Huge crowd in Charleston at the @WVGOP vi...   \n",
       "664655    https://t.co/0QmZlRfEcD https://t.co/FY520NC2GB   \n",
       "\n",
       "                                                   tokens  \\\n",
       "0       [brooks, joins, alabama, delegation, voting, f...   \n",
       "1       [brooks, senate, democrats, allowing, presiden...   \n",
       "2       [nasa, square, event, sat, 11am, â€“, 4pm, stop,...   \n",
       "3       [trouble, socialism, eventually, run, peoples,...   \n",
       "4       [trouble, socialism, eventually, run, peoples,...   \n",
       "...                                                   ...   \n",
       "664651  [great, time, wvu, homecoming, parade, yesterd...   \n",
       "664652  [need, transparency, washington, #wvpol, https...   \n",
       "664653  [saw, double, standard, dc, rules, simply, don...   \n",
       "664654  [wow, huge, crowd, charleston, wvgop, victory,...   \n",
       "664655           [httpstco0qmzlrfecd, httpstcofy520nc2gb]   \n",
       "\n",
       "                                                cleantext  \n",
       "0       brooks joins alabama delegation in voting agai...  \n",
       "1       brooks senate democrats allowing president to ...  \n",
       "2       nasa on the square event this sat 11am â€“ 4pm s...  \n",
       "3       the trouble with socialism is that eventually ...  \n",
       "4       the trouble with socialism is eventually you r...  \n",
       "...                                                   ...  \n",
       "664651  we had a great time at the wvu homecoming para...  \n",
       "664652  we need more transparency in washington #wvpol...  \n",
       "664653  we saw there is a double standard in dc and th...  \n",
       "664654  wow huge crowd in charleston at the wvgop vict...  \n",
       "664655              httpstco0qmzlrfecd httpstcofy520nc2gb  \n",
       "\n",
       "[664656 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = resultsdf[[\"cleantext\", \"party\"]]\n",
    "tweet_data = query_results.values.tolist()\n",
    "#tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 51762 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in tweet_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in tweet_data]\n",
    "tweet_data = featuresets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(tweet_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: {'earlier': True, 'today': True, 'i': True, 'spoke': True, 'on': True, 'the': True, 'house': True, 'floor': True, 'abt': True, 'protecting': True, 'health': True, 'care': True, 'for': True, 'women': True, 'and': True, 'praised': True, 'their': True, 'work': True, 'central': True, 'coast': True}\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'go': True, 'tribe': True, '#rallytogether': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'apparently': True, 'trump': True, 'thinks': True, 'its': True, 'just': True, 'too': True, 'easy': True, 'for': True, 'students': True, 'overwhelmed': True, 'by': True, 'the': True, 'crushing': True, 'burden': True, 'of': True, 'debt': True, 'to': True, 'pay': True, 'off': True, 'student': True, 'loans': True, '#trumpbudget': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'weâ€™re': True, 'grateful': True, 'for': True, 'our': True, 'first': True, 'responders': True, 'rescue': True, 'personnel': True, 'firefighters': True, 'police': True, 'and': True, 'volunteers': True, 'who': True, 'have': True, 'been': True, 'working': True, 'tirelessly': True, 'to': True, 'keep': True, 'people': True, 'safe': True, 'provide': True, 'muchneeded': True, 'help': True, 'while': True, 'putting': True, 'their': True, 'own': True, 'lives': True, 'on': True, 'the': True, 'line': True}\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'letâ€™s': True, 'make': True, 'it': True, 'even': True, 'greater': True, '#kag': True, 'ðŸ‡ºðŸ‡¸': True}\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: {'we': True, 'have': True, 'about': True, 'until': True, 'the': True, 'cavs': True, 'tie': True, 'up': True, 'series': True, '22': True, 'im': True, '#allin216': True, 'repbarbaralee': True, 'you': True, 'scared': True, '#roadtovictory': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'congrats': True, 'to': True, 'on': True, 'his': True, 'new': True, 'gig': True, 'at': True, 'sd': True, 'city': True, 'hall': True, 'we': True, 'are': True, 'glad': True, 'you': True, 'will': True, 'continue': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'we': True, 'are': True, 'really': True, 'close': True, 'have': True, 'over': True, '3500': True, 'raised': True, 'toward': True, 'the': True, 'match': True, 'right': True, 'now': True, 'thatâ€™s': True, '7000': True, 'for': True, 'majors': True, 'in': True, 'room': True, 'ðŸ˜‚': True, 'help': True, 'us': True, 'get': True, 'there': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'today': True, 'the': True, 'comment': True, 'period': True, 'for': True, 'potusâ€™s': True, 'plan': True, 'to': True, 'expand': True, 'offshore': True, 'drilling': True, 'opened': True, 'public': True, 'you': True, 'have': True, '60': True, 'days': True, 'until': True, 'march': True, '9': True, 'share': True, 'why': True, 'oppose': True, 'proposed': True, 'program': True, 'directly': True, 'with': True, 'trump': True, 'administration': True, 'comments': True, 'can': True, 'be': True, 'made': True, 'by': True, 'email': True, 'or': True, 'mail': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: {'celebrated': True, '22': True, 'years': True, 'of': True, 'eastside': True, 'commitment': True, 'saluted': True, 'community': True, 'leaders': True, 'at': True, 'last': True, 'nightâ€™s': True, 'awards': True, 'dinner': True}\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(tweet)\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48471991526443753\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, tweet_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     and = True           Republ : Democr =      3.0 : 1.0\n",
      "                    help = True           Republ : Democr =      3.0 : 1.0\n",
      "                   their = True           Republ : Democr =      3.0 : 1.0\n",
      "                    #kag = None           Democr : Republ =      1.9 : 1.0\n",
      "                    been = None           Democr : Republ =      1.9 : 1.0\n",
      "                    even = None           Democr : Republ =      1.9 : 1.0\n",
      "            firefighters = None           Democr : Republ =      1.9 : 1.0\n",
      "                   first = None           Democr : Republ =      1.9 : 1.0\n",
      "                grateful = None           Democr : Republ =      1.9 : 1.0\n",
      "                 greater = None           Democr : Republ =      1.9 : 1.0\n",
      "                      it = None           Democr : Republ =      1.9 : 1.0\n",
      "                    keep = None           Democr : Republ =      1.9 : 1.0\n",
      "                   letâ€™s = None           Democr : Republ =      1.9 : 1.0\n",
      "                    line = None           Democr : Republ =      1.9 : 1.0\n",
      "                   lives = None           Democr : Republ =      1.9 : 1.0\n",
      "                    make = None           Democr : Republ =      1.9 : 1.0\n",
      "              muchneeded = None           Democr : Republ =      1.9 : 1.0\n",
      "                     our = None           Democr : Republ =      1.9 : 1.0\n",
      "                     own = None           Democr : Republ =      1.9 : 1.0\n",
      "                  people = None           Democr : Republ =      1.9 : 1.0\n",
      "               personnel = None           Democr : Republ =      1.9 : 1.0\n",
      "                  police = None           Democr : Republ =      1.9 : 1.0\n",
      "                 provide = None           Democr : Republ =      1.9 : 1.0\n",
      "                 putting = None           Democr : Republ =      1.9 : 1.0\n",
      "                  rescue = None           Democr : Republ =      1.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(tweet)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 1408, 'Democratic': 2870}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 2303, 'Democratic': 3421})})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "Looking at our most important features, I see that the indicativeness of our key words is a lot lower than for the congressional db data, perhaps due to the smaller sample size. Our accuracy on the dataset as a whole though is slightly higher -- 48%.\n",
    "\n",
    "Our key words (aka most important features) don't seem to be as keenly associated as the congressional db was. I can't quite create the connection between the party and the keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
